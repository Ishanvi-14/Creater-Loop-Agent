{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "### üîë Setup: API Key Loading and Package Installation\n",
        "\n",
        "This cell installs necessary libraries and securely loads the Gemini API Key from the environment/ Secrets. This is the foundational step for all subsequent agent interactions."
      ],
      "metadata": {
        "id": "McDgyhcGLgi1"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oYJ1EG1g9jZd",
        "outputId": "962e141d-91f6-4310-ac86-c46ccf71e5f6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "‚úÖ Gemini API Key loaded from Kaggle Secrets.\n"
          ]
        }
      ],
      "source": [
        "# Cell 1 ‚Äî Install + Load Gemini API key from Kaggle Secrets\n",
        "\n",
        "!pip install -q google-genai python-dotenv gradio\n",
        "\n",
        "import os\n",
        "from google.colab import userdata\n",
        "\n",
        "# load Gemini API key from Kaggle Secrets\n",
        "\n",
        "api_key = userdata.get(\"GEMINI_API_KEY\")\n",
        "\n",
        "if not api_key:\n",
        "    raise ValueError(\"GEMINI_API_KEY is not defined in Kaggle Secrets.\")\n",
        "\n",
        "os.environ[\"GEMINI_API_KEY\"] = api_key\n",
        "\n",
        "print(\"‚úÖ Gemini API Key loaded from Kaggle Secrets.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### ‚öôÔ∏è Core Configuration and LLM Utility\n",
        "\n",
        "Sets up the Gemini client, defines the model (`gemini-2.5-flash`), and includes the central `llm_call` function. This utility abstracts the LLM interaction, allowing the subsequent agents to focus purely on their reasoning and data flow.### üß† MemoryBank: Long-Term State Management\n",
        "\n",
        "This class implements the **Long Term Memory** concept. It uses a JSON-backed structure to persist the creator's profile, a history of **Past Content Plans** (including detailed **Check-in History**), and identified **Failure Patterns**. This memory is critical for the `MemoryAgent` and `AccountabilityAgent` to learn and provide personalized advice."
      ],
      "metadata": {
        "id": "bE3fk1qGLqw_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Cell 2: Imports & configuration\n",
        "\n",
        "from typing import Any, Dict, List\n",
        "from datetime import datetime, timedelta\n",
        "import json\n",
        "import os\n",
        "import uuid\n",
        "import re # Added regex import for StrategistAgent\n",
        "\n",
        "from google import genai\n",
        "from dotenv import load_dotenv\n",
        "\n",
        "import gradio as gr\n",
        "\n",
        "# Load .env if present (harmless)\n",
        "load_dotenv()\n",
        "\n",
        "GEMINI_MODEL = \"gemini-2.5-flash\"\n",
        "\n",
        "\n",
        "def get_client() -> genai.Client:\n",
        "    \"\"\"\n",
        "    Returns a configured Gemini client.\n",
        "    Reads API key from GEMINI_API_KEY.\n",
        "    \"\"\"\n",
        "    api_key = os.getenv(\"GEMINI_API_KEY\")\n",
        "    if not api_key:\n",
        "        raise RuntimeError(\"GEMINI_API_KEY is not set. Set it in Cell 1 or via environment.\")\n",
        "    client = genai.Client(api_key=api_key)\n",
        "    return client\n",
        "\n",
        "\n",
        "# Global Gemini client (lazy init)\n",
        "_CLIENT: genai.Client | None = None\n",
        "\n",
        "\n",
        "def llm_call(prompt: str) -> str:\n",
        "    \"\"\"\n",
        "    Simple helper to call Gemini with a text prompt.\n",
        "    \"\"\"\n",
        "    global _CLIENT\n",
        "    if _CLIENT is None:\n",
        "        _CLIENT = get_client()\n",
        "\n",
        "    resp = _CLIENT.models.generate_content(\n",
        "        model=GEMINI_MODEL,\n",
        "        contents=prompt,\n",
        "    )\n",
        "    return resp.text\n",
        "\n",
        "\n",
        "def now_utc() -> datetime:\n",
        "    return datetime.utcnow()"
      ],
      "metadata": {
        "id": "5GxrRYrg9wVd"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "3V63ZN8WLx-m"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### üß† MemoryBank: Long-Term State Management\n",
        "\n",
        "This class implements the **Long Term Memory** concept. It uses a JSON-backed structure to persist the creator's profile, a history of **Past Content Plans** (including detailed **Check-in History**), and identified **Failure Patterns**. This memory is critical for the `MemoryAgent` and `AccountabilityAgent` to learn and provide personalized advice."
      ],
      "metadata": {
        "id": "WqZEq0pFLyJD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Cell 3: MemoryBank ‚Äì JSON-backed long-term memory (with check-in history support)\n",
        "\n",
        "class MemoryBank:\n",
        "    \"\"\"\n",
        "    Tiny JSON-backed memory bank.\n",
        "\n",
        "    Structure:\n",
        "    {\n",
        "      \"user_profile\": {...} or null,\n",
        "      \"past_content\": [ContentPlan, ...],\n",
        "      \"failure_patterns\": [FailurePattern, ...],\n",
        "      \"accountability_states\": [ ... ]\n",
        "    }\n",
        "\n",
        "    Each ContentPlan may contain a \"checkins\": [ {timestamp, completed_ids, blockers, energy, coaching_excerpt}, ... ]\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, path: str = \"memory.json\"):\n",
        "        self.path = path\n",
        "        self.state = {\n",
        "            \"user_profile\": None,\n",
        "            \"past_content\": [],\n",
        "            \"failure_patterns\": [],\n",
        "            \"accountability_states\": [],\n",
        "        }\n",
        "        self._load()\n",
        "\n",
        "    def _load(self):\n",
        "        if os.path.exists(self.path):\n",
        "            try:\n",
        "                with open(self.path, \"r\", encoding=\"utf-8\") as f:\n",
        "                    self.state = json.load(f)\n",
        "            except Exception:\n",
        "                # If corrupted, reset\n",
        "                self.state = {\n",
        "                    \"user_profile\": None,\n",
        "                    \"past_content\": [],\n",
        "                    \"failure_patterns\": [],\n",
        "                    \"accountability_states\": [],\n",
        "                }\n",
        "\n",
        "    def _save(self):\n",
        "        with open(self.path, \"w\", encoding=\"utf-8\") as f:\n",
        "            json.dump(self.state, f, indent=2)\n",
        "\n",
        "    # ---------- User profile ----------\n",
        "\n",
        "    def get_user_profile(self) -> Dict[str, Any] | None:\n",
        "        return self.state.get(\"user_profile\")\n",
        "\n",
        "    def set_user_profile(self, profile: Dict[str, Any]):\n",
        "        self.state[\"user_profile\"] = profile\n",
        "        self._save()\n",
        "\n",
        "    # ---------- Content plans ----------\n",
        "\n",
        "    def add_content_plan(self, plan: Dict[str, Any]):\n",
        "        # ensure checkins key exists\n",
        "        if \"checkins\" not in plan:\n",
        "            plan[\"checkins\"] = []\n",
        "        self.state[\"past_content\"].append(plan)\n",
        "        self._save()\n",
        "\n",
        "    def update_content_plan(self, plan_id: str, updates: Dict[str, Any]):\n",
        "        for idx, plan in enumerate(self.state[\"past_content\"]):\n",
        "            if plan.get(\"id\") == plan_id:\n",
        "                # preserve existing checkins if not in updates\n",
        "                if \"checkins\" not in updates and \"checkins\" in plan:\n",
        "                    updates[\"checkins\"] = plan[\"checkins\"]\n",
        "                self.state[\"past_content\"][idx].update(updates)\n",
        "                self._save()\n",
        "                return self.state[\"past_content\"][idx]\n",
        "        return None\n",
        "\n",
        "    def get_content_plan(self, plan_id: str) -> Dict[str, Any] | None:\n",
        "        for plan in self.state[\"past_content\"]:\n",
        "            if plan.get(\"id\") == plan_id:\n",
        "                # guarantee checkins key\n",
        "                if \"checkins\" not in plan:\n",
        "                    plan[\"checkins\"] = []\n",
        "                    self._save()\n",
        "                return plan\n",
        "        return None\n",
        "\n",
        "    def list_content_plans(self) -> List[Dict[str, Any]]:\n",
        "        return self.state[\"past_content\"]\n",
        "\n",
        "    # ---------- Failure patterns ----------\n",
        "\n",
        "    def list_failure_patterns(self) -> List[Dict[str, Any]]:\n",
        "        return self.state[\"failure_patterns\"]\n",
        "\n",
        "    def increment_failure_pattern(self, trigger: str, description: str | None = None):\n",
        "        patterns = self.state[\"failure_patterns\"]\n",
        "        for fp in patterns:\n",
        "            if fp.get(\"trigger\") == trigger:\n",
        "                fp[\"evidence_count\"] = fp.get(\"evidence_count\", 0) + 1\n",
        "                break\n",
        "        else:\n",
        "            patterns.append(\n",
        "                {\n",
        "                    \"pattern_id\": f\"fp_{len(patterns) + 1}\",\n",
        "                    \"trigger\": trigger,\n",
        "                    \"description\": description or trigger,\n",
        "                    \"evidence_count\": 1,\n",
        "                }\n",
        "            )\n",
        "        self._save()\n",
        "\n",
        "    # ---------- Accountability states ----------\n",
        "\n",
        "    def upsert_accountability_state(self, state: Dict[str, Any]):\n",
        "        cps_id = state.get(\"content_plan_id\")\n",
        "        existing = None\n",
        "        for s in self.state[\"accountability_states\"]:\n",
        "            if s.get(\"content_plan_id\") == cps_id:\n",
        "                existing = s\n",
        "                break\n",
        "        if existing:\n",
        "            existing.update(state)\n",
        "        else:\n",
        "            self.state[\"accountability_states\"].append(state)\n",
        "        self._save()\n",
        "\n",
        "    def get_accountability_state(self, content_plan_id: str) -> Dict[str, Any] | None:\n",
        "        for s in self.state[\"accountability_states\"]:\n",
        "            if s.get(\"content_plan_id\") == content_plan_id:\n",
        "                return s\n",
        "        return None\n",
        "\n",
        "    # ---------- Check-in history helper ----------\n",
        "\n",
        "    def append_checkin(self, plan_id: str, record: Dict[str, Any]):\n",
        "        plan = self.get_content_plan(plan_id)\n",
        "        if not plan:\n",
        "            return False\n",
        "        if \"checkins\" not in plan:\n",
        "            plan[\"checkins\"] = []\n",
        "        plan[\"checkins\"].append(record)\n",
        "        self.update_content_plan(plan_id, plan)\n",
        "        return True"
      ],
      "metadata": {
        "id": "NPhd6AmL-KJ2"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### üõ†Ô∏è Custom Tools and Observability (Logging)\n",
        "\n",
        "Defines two core **Custom Tools** (`search_trends` and `seo_keyword_tool`) simulated using the LLM to research trends and optimize titles/keywords. It also implements the **Logging** framework (`log_event`) for basic observability, allowing users to trace the agent sequence and inputs/outputs."
      ],
      "metadata": {
        "id": "xDY0th9cL8Qn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Cell 4: Tools ‚Äì logging, pseudo-search, SEO tool\n",
        "\n",
        "LOGS: List[Dict[str, Any]] = []\n",
        "\n",
        "\n",
        "def log_event(agent: str, input_summary: str, output_summary: str):\n",
        "    LOGS.append(\n",
        "        {\n",
        "            \"timestamp\": now_utc().isoformat(timespec=\"seconds\"),\n",
        "            \"agent\": agent,\n",
        "            \"input\": input_summary,\n",
        "            \"output\": (output_summary or \"\")[:400],\n",
        "        }\n",
        "    )\n",
        "\n",
        "\n",
        "def get_logs() -> List[Dict[str, Any]]:\n",
        "    return LOGS\n",
        "\n",
        "\n",
        "def search_trends(niche: str, platform: str) -> Dict[str, Any]:\n",
        "    \"\"\"\n",
        "    'Search' tool using Gemini as a research assistant.\n",
        "    In the writeup you can describe this as a tool abstraction.\n",
        "    \"\"\"\n",
        "    prompt = f\"\"\"\n",
        "You are a research assistant for a {platform} content creator in the niche: \"{niche}\".\n",
        "\n",
        "1. List 3‚Äì5 currently hot themes or topics in this niche.\n",
        "2. For each, give:\n",
        "   - A short description\n",
        "   - The typical hook/angle creators are using\n",
        "3. Suggest 3 concrete content directions for a solo creator.\n",
        "\n",
        "Respond clearly in bullet points.\n",
        "\"\"\"\n",
        "    text = llm_call(prompt)\n",
        "    log_event(\"TrendTool\", f\"niche={niche}, platform={platform}\", text)\n",
        "    return {\"raw_summary\": text}\n",
        "\n",
        "\n",
        "def seo_keyword_tool(topic: str, niche: str, platform: str) -> Dict[str, Any]:\n",
        "    \"\"\"\n",
        "    Custom SEO tool: titles, keywords, tags.\n",
        "    \"\"\"\n",
        "    prompt = f\"\"\"\n",
        "You are an SEO assistant for a {platform} creator in the niche \"{niche}\".\n",
        "\n",
        "For the topic:\n",
        "\"{topic}\"\n",
        "\n",
        "Generate:\n",
        "1) 3-5 strongly optimized titles.\n",
        "2) 1 primary keyword.\n",
        "3) 5-10 secondary/long-tail keywords.\n",
        "4) 8-15 tags/hashtags.\n",
        "\n",
        "Return in this structured markdown form:\n",
        "\n",
        "TITLES:\n",
        "- ...\n",
        "\n",
        "PRIMARY_KEYWORD:\n",
        "- ...\n",
        "\n",
        "SECONDARY_KEYWORDS:\n",
        "- ...\n",
        "\n",
        "TAGS:\n",
        "- ...\n",
        "\"\"\"\n",
        "    text = llm_call(prompt)\n",
        "    log_event(\"SEOTool\", f\"topic={topic}\", text)\n",
        "    return {\"raw_seo_text\": text}"
      ],
      "metadata": {
        "id": "HxXgbNM0-MwE"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### ü§ñ Multi-Agent System Core\n",
        "\n",
        "This cell defines the four specialized agents, demonstrating **Multi-Agent System**, **Parallel Agents**, **Sequential Agents**, **Loop Agents**, and the **A2A Protocol**:\n",
        "\n",
        "1.  **TrendAgent:** Gathers external (simulated) trend data (inputs to Strategist).\n",
        "2.  **MemoryAgent:** Analyzes historical data from the `MemoryBank` (Parallel to Trend, inputs to Strategist).\n",
        "3.  **StrategistAgent:** The central brain. It takes the insights from Trend and Memory, uses the SEO **Tool**, and generates a full content plan. It performs an **A2A Handoff** of the plan's tasks to the Accountability Agent.\n",
        "4.  **AccountabilityAgent:** The **Loop Agent**. It handles user check-ins, updates task status, calculates progress, identifies **Failure Patterns**, and provides **Micro-Coaching** using the LLM."
      ],
      "metadata": {
        "id": "96k5_Bo7MJHR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Cell 5: Agents ‚Äì Trend, Memory, Strategist, Accountability (Final Corrected Version)\n",
        "\n",
        "class BaseAgent:\n",
        "    def __init__(self, name: str, memory: MemoryBank):\n",
        "        self.name = name\n",
        "        self.memory = memory\n",
        "\n",
        "    def log(self, input_summary: str, output_summary: str):\n",
        "        log_event(self.name, input_summary, output_summary)\n",
        "\n",
        "\n",
        "# ---------- Trend Agent ----------\n",
        "\n",
        "class TrendAgent(BaseAgent):\n",
        "    \"\"\"\n",
        "    Agent A: Researches what's trending in the niche/platform.\n",
        "    \"\"\"\n",
        "\n",
        "    def run(\n",
        "        self,\n",
        "        niche: str,\n",
        "        platform: str\n",
        "    ) -> Dict[str, Any]:\n",
        "        result = search_trends(niche, platform)\n",
        "        self.log(f\"niche={niche}, platform={platform}\", result[\"raw_summary\"])\n",
        "        return {\n",
        "            \"trend_summary\": result[\"raw_summary\"],\n",
        "        }\n",
        "\n",
        "\n",
        "# ---------- Memory Agent ----------\n",
        "\n",
        "class MemoryAgent(BaseAgent):\n",
        "    \"\"\"\n",
        "    Agent B: Summarizes what has historically worked for this creator.\n",
        "    \"\"\"\n",
        "\n",
        "    def run(self) -> Dict[str, Any]:\n",
        "        user_profile = self.memory.get_user_profile() or {}\n",
        "        past_content = self.memory.list_content_plans()\n",
        "        failure_patterns = self.memory.list_failure_patterns()\n",
        "\n",
        "        prompt = f\"\"\"\n",
        "You are analyzing historical performance for a solo creator.\n",
        "\n",
        "USER PROFILE:\n",
        "{user_profile}\n",
        "\n",
        "PAST CONTENT PLANS:\n",
        "{past_content}\n",
        "\n",
        "FAILURE PATTERNS:\n",
        "{failure_patterns}\n",
        "\n",
        "1. Summarize which formats and tones seem to work best.\n",
        "2. Note any topics/styles that did NOT work well (if any).\n",
        "3. Summarize common blockers or failure patterns.\n",
        "4. Give concise recommendations to improve the next content plan.\n",
        "\"\"\"\n",
        "        text = llm_call(prompt)\n",
        "        self.log(\"Analyze memory\", text)\n",
        "        return {\n",
        "            \"memory_insights\": text,\n",
        "        }\n",
        "\n",
        "\n",
        "# ---------- Strategist Agent ----------\n",
        "\n",
        "class StrategistAgent(BaseAgent):\n",
        "    \"\"\"\n",
        "    Agent C: Combines trend + memory to create a content plan\n",
        "    + 48h production tasks.\n",
        "    \"\"\"\n",
        "\n",
        "    def run(\n",
        "        self,\n",
        "        trend_result: Dict[str, Any],\n",
        "        memory_result: Dict[str, Any],\n",
        "        time_window_hours: int = 48,\n",
        "    ) -> Dict[str, Any]:\n",
        "        user_profile = self.memory.get_user_profile() or {}\n",
        "        platform = user_profile.get(\"platform\", \"youtube\")\n",
        "        niche = user_profile.get(\"niche\", \"general\")\n",
        "\n",
        "        # Choose topic\n",
        "        prompt_topic = f\"\"\"\n",
        "You are the Strategist Agent for a solo {platform} creator in niche \"{niche}\".\n",
        "\n",
        "TRENDS:\n",
        "{trend_result['trend_summary']}\n",
        "\n",
        "MEMORY INSIGHTS:\n",
        "{memory_result['memory_insights']}\n",
        "\n",
        "1. Propose ONE best-fit topic for the next content piece.\n",
        "2. Explain in 3-4 sentences why this topic fits.\n",
        "3. Suggest a clear angle/hook.\n",
        "\n",
        "Return:\n",
        "\n",
        "TOPIC:\n",
        "...\n",
        "\n",
        "RATIONALE:\n",
        "...\n",
        "\"\"\"\n",
        "        topic_response = llm_call(prompt_topic)\n",
        "        self.log(\"Choose topic\", topic_response)\n",
        "\n",
        "        topic_line = \"Content idea\"\n",
        "        # Robust extraction: find content between 'TOPIC:' and 'RATIONALE:'\n",
        "        match = re.search(r\"TOPIC:\\s*(.*?)\\s*RATIONALE:\", topic_response, re.DOTALL | re.IGNORECASE)\n",
        "        if match:\n",
        "            topic_line = match.group(1).strip()\n",
        "        else:\n",
        "            # Fallback to naive extraction if regex fails\n",
        "            lines = topic_response.splitlines()\n",
        "            seen_topic = False\n",
        "            for line in lines:\n",
        "                if line.strip().upper().startswith(\"TOPIC:\"):\n",
        "                    seen_topic = True\n",
        "                    continue\n",
        "                if seen_topic and line.strip() and not line.strip().upper().startswith(\"RATIONALE:\"):\n",
        "                    topic_line = line.strip()\n",
        "                    break\n",
        "\n",
        "        # SEO tool\n",
        "        seo_result = seo_keyword_tool(topic_line, niche, platform)\n",
        "\n",
        "        # Outline & production steps\n",
        "        prompt_outline = f\"\"\"\n",
        "You are the Strategist Agent.\n",
        "\n",
        "Create:\n",
        "1. A 5-10 bullet outline for content with topic \"{topic_line}\" for {platform}.\n",
        "2. A 4-6 step list of production tasks (script, record, edit, upload, thumbnail, etc.)\n",
        "   for a creator who has about {time_window_hours} hours spread over 2 days.\n",
        "\n",
        "Return clearly with headings:\n",
        "\n",
        "OUTLINE:\n",
        "- ...\n",
        "\n",
        "PRODUCTION_STEPS:\n",
        "- ...\n",
        "\"\"\"\n",
        "        outline_text = llm_call(prompt_outline)\n",
        "        self.log(\"Outline + steps\", outline_text)\n",
        "\n",
        "        # Simplified fixed task schedule (to avoid JSON parsing issues)\n",
        "        now = now_utc()\n",
        "        deadline = now + timedelta(hours=time_window_hours)\n",
        "\n",
        "        default_tasks = [\n",
        "            \"Draft script\",\n",
        "            \"Polish script & finalize outline\",\n",
        "            \"Record video/audio\",\n",
        "            \"Edit content\",\n",
        "            \"Upload & publish with title/tags/thumbnail\",\n",
        "        ]\n",
        "        tasks: List[Dict[str, Any]] = []\n",
        "        step_duration = (\n",
        "            max(time_window_hours // len(default_tasks), 4)\n",
        "            if time_window_hours >= len(default_tasks)\n",
        "            else 4\n",
        "        )\n",
        "\n",
        "        for idx, desc in enumerate(default_tasks):\n",
        "            tasks.append(\n",
        "                {\n",
        "                    \"task_id\": f\"task_{idx+1}\",\n",
        "                    \"description\": desc,\n",
        "                    \"status\": \"pending\",\n",
        "                    # Corrected timespec to seconds for consistency (fixing previous syntax error in unshown versions)\n",
        "                    \"due_time\": (now + timedelta(hours=step_duration * (idx + 1))).isoformat(timespec=\"seconds\"),\n",
        "                    \"last_update\": now.isoformat(timespec=\"minutes\"),\n",
        "                    \"notes\": \"\",\n",
        "                }\n",
        "            )\n",
        "\n",
        "        plan_id = f\"plan_{uuid.uuid4().hex[:8]}\"\n",
        "\n",
        "        content_plan = {\n",
        "            \"id\": plan_id,\n",
        "            \"created_at\": now.isoformat(timespec=\"minutes\"),\n",
        "            \"topic\": topic_line,\n",
        "            \"trend_summary\": trend_result[\"trend_summary\"],\n",
        "            \"memory_insights\": memory_result[\"memory_insights\"],\n",
        "            \"seo_raw\": seo_result[\"raw_seo_text\"],\n",
        "            \"outline_raw\": outline_text,\n",
        "            \"tasks\": tasks,\n",
        "            \"deadline\": deadline.isoformat(timespec=\"minutes\"),\n",
        "            \"status\": \"active\",\n",
        "            \"checkins\": [],\n",
        "        }\n",
        "\n",
        "        # Store in memory bank\n",
        "        self.memory.add_content_plan(content_plan)\n",
        "\n",
        "        # A2A handoff payload for Accountability agent\n",
        "        handoff_payload = {\n",
        "            \"content_plan_id\": plan_id,\n",
        "            \"tasks\": tasks,\n",
        "            \"deadline\": content_plan[\"deadline\"],\n",
        "        }\n",
        "\n",
        "        return handoff_payload\n",
        "\n",
        "\n",
        "# ---------- Accountability Agent ----------\n",
        "\n",
        "class AccountabilityAgent(BaseAgent):\n",
        "    \"\"\"\n",
        "    Agent D: Loop-style agent for check-ins, updates tasks,\n",
        "    learns failure patterns, and gives micro-coaching.\n",
        "\n",
        "    Here, each Gradio submit simulates one \"tick\" of the loop.\n",
        "    \"\"\"\n",
        "\n",
        "    def initialize_state(self, handoff: Dict[str, Any]):\n",
        "        state = {\n",
        "            \"content_plan_id\": handoff[\"content_plan_id\"],\n",
        "            \"tasks\": handoff[\"tasks\"],\n",
        "            \"deadline\": handoff[\"deadline\"],\n",
        "            \"next_check_in\": now_utc().isoformat(timespec=\"minutes\"),\n",
        "            \"check_in_interval_hours\": 6,\n",
        "            \"completed\": False,\n",
        "        }\n",
        "        self.memory.upsert_accountability_state(state)\n",
        "\n",
        "    def run_check_in(\n",
        "        self,\n",
        "        content_plan_id: str,\n",
        "        user_updates: Dict[str, Any],\n",
        "    ) -> Dict[str, Any]:\n",
        "        state = self.memory.get_accountability_state(content_plan_id)\n",
        "        if not state:\n",
        "            raise ValueError(f\"No accountability state found for {content_plan_id}\")\n",
        "\n",
        "        plan = self.memory.get_content_plan(content_plan_id)\n",
        "        if not plan:\n",
        "            raise ValueError(f\"No content plan found for {content_plan_id}\")\n",
        "\n",
        "        now = now_utc()\n",
        "        tasks = plan[\"tasks\"]\n",
        "\n",
        "        # 1. Update tasks\n",
        "        completed_ids = set(user_updates.get(\"completed_task_ids\", []))\n",
        "        for t in tasks:\n",
        "            if t[\"task_id\"] in completed_ids:\n",
        "                t[\"status\"] = \"done\"\n",
        "                t[\"last_update\"] = now.isoformat(timespec=\"minutes\")\n",
        "\n",
        "        blockers = user_updates.get(\"blockers\", \"\")\n",
        "        energy = user_updates.get(\"energy_level\", None)\n",
        "\n",
        "        # 2. Missed tasks -> failure patterns\n",
        "        for t in tasks:\n",
        "            try:\n",
        "                # Due time uses 'seconds' from StrategistAgent\n",
        "                due = datetime.fromisoformat(t[\"due_time\"])\n",
        "            except Exception:\n",
        "                continue\n",
        "            if t[\"status\"] != \"done\" and now > due:\n",
        "                trigger = f\"{t['description']} after {due.hour}:00\"\n",
        "                self.memory.increment_failure_pattern(\n",
        "                    trigger,\n",
        "                    description=f\"User tends to miss '{t['description']}' when scheduled after {due.hour}:00\",\n",
        "                )\n",
        "\n",
        "        # 3. Completed?\n",
        "        all_done = all(t[\"status\"] == \"done\" for t in tasks)\n",
        "        if all_done:\n",
        "            plan[\"status\"] = \"completed\"\n",
        "            state[\"completed\"] = True\n",
        "        else:\n",
        "            interval_h = state.get(\"check_in_interval_hours\", 6)\n",
        "            state[\"next_check_in\"] = (now + timedelta(hours=interval_h)).isoformat(timespec=\"minutes\")\n",
        "\n",
        "        # Persist task updates\n",
        "        plan[\"tasks\"] = tasks\n",
        "        # We'll append a compact checkin record to the plan's checkins list\n",
        "        # 4. Coaching\n",
        "        failure_patterns = self.memory.list_failure_patterns()\n",
        "        prompt = f\"\"\"\n",
        "You are the Accountability Agent for a solo creator.\n",
        "\n",
        "CURRENT PLAN:\n",
        "{plan}\n",
        "\n",
        "FAILURE PATTERNS:\n",
        "{failure_patterns}\n",
        "\n",
        "USER UPDATE:\n",
        "Blockers: {blockers}\n",
        "Energy level (1-5): {energy}\n",
        "\n",
        "1. Summarize their current progress.\n",
        "2. Give 2-3 specific, kind but firm coaching suggestions.\n",
        "3. Mention any repeating patterns you see.\n",
        "\n",
        "Be concise but actionable.\n",
        "\"\"\"\n",
        "        coaching = llm_call(prompt)\n",
        "        # record a short excerpt for history\n",
        "        coaching_excerpt = coaching.strip().replace(\"\\n\", \" \")[:500]\n",
        "\n",
        "        self.memory.append_checkin(\n",
        "            plan[\"id\"],\n",
        "            {\n",
        "                \"timestamp\": now.isoformat(timespec=\"minutes\"),\n",
        "                \"completed_ids\": list(completed_ids),\n",
        "                \"blockers\": blockers,\n",
        "                \"energy\": energy,\n",
        "                \"coaching_excerpt\": coaching_excerpt,\n",
        "            },\n",
        "        )\n",
        "\n",
        "        # Save updated plan & state\n",
        "        self.memory.update_content_plan(plan[\"id\"], plan)\n",
        "        self.memory.upsert_accountability_state(state)\n",
        "\n",
        "        # log\n",
        "        self.log(\"Check-in + coaching\", coaching)\n",
        "\n",
        "        return {\n",
        "            \"plan_status\": plan[\"status\"],\n",
        "            \"tasks\": tasks,\n",
        "            \"coaching\": coaching,\n",
        "            \"next_check_in\": state.get(\"next_check_in\"),\n",
        "            \"checkins\": plan.get(\"checkins\", []),\n",
        "        }"
      ],
      "metadata": {
        "id": "L5gAc17i-Pns"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### üîÅ Orchestrator and Full Planning Cycle\n",
        "\n",
        "These functions manage the **Sequential Agent** flow:\n",
        "1.  Ensures the User Profile is set (`ensure_user_profile`).\n",
        "2.  Executes the full planning process (`run_full_planning_cycle`) by running the **TrendAgent** and **MemoryAgent** conceptually in parallel, feeding their results to the **StrategistAgent**, and initializing the **AccountabilityAgent** state via the A2A handoff."
      ],
      "metadata": {
        "id": "AILfsJoFMNGN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Cell 6: Orchestrator helpers\n",
        "\n",
        "GLOBAL_MEMORY = MemoryBank()  # shared across app lifetime\n",
        "\n",
        "\n",
        "def ensure_user_profile(\n",
        "    name: str,\n",
        "    niche: str,\n",
        "    platform: str = \"youtube\",\n",
        "    upload_goal_per_week: int = 1,\n",
        ") -> Dict[str, Any]:\n",
        "    existing = GLOBAL_MEMORY.get_user_profile()\n",
        "    if existing:\n",
        "        existing.update(\n",
        "            {\n",
        "                \"name\": name,\n",
        "                \"niche\": niche,\n",
        "                \"platform\": platform,\n",
        "                \"upload_goal_per_week\": upload_goal_per_week,\n",
        "            }\n",
        "        )\n",
        "        GLOBAL_MEMORY.set_user_profile(existing)\n",
        "        return existing\n",
        "\n",
        "    profile = {\n",
        "        \"name\": name,\n",
        "        \"niche\": niche,\n",
        "        \"platform\": platform,\n",
        "        \"upload_goal_per_week\": upload_goal_per_week,\n",
        "        \"preferred_length\": \"medium\",\n",
        "        \"work_hours\": {\"start\": \"18:00\", \"end\": \"23:00\"},\n",
        "        \"known_pain_points\": [],\n",
        "    }\n",
        "    GLOBAL_MEMORY.set_user_profile(profile)\n",
        "    return profile\n",
        "\n",
        "\n",
        "def run_full_planning_cycle(\n",
        "    name: str,\n",
        "    niche: str,\n",
        "    platform: str = \"youtube\",\n",
        "    time_window_hours: int = 48,\n",
        ") -> Dict[str, Any]:\n",
        "    \"\"\"\n",
        "    1. Ensure user profile in memory.\n",
        "    2. Run TrendAgent + MemoryAgent (\"parallel\").\n",
        "    3. Run StrategistAgent; store content plan.\n",
        "    4. Initialize AccountabilityAgent state.\n",
        "    \"\"\"\n",
        "    user_profile = ensure_user_profile(name, niche, platform)\n",
        "\n",
        "    trend_agent = TrendAgent(\"TrendAgent\", GLOBAL_MEMORY)\n",
        "    memory_agent = MemoryAgent(\"MemoryAgent\", GLOBAL_MEMORY)\n",
        "    strategist = StrategistAgent(\"StrategistAgent\", GLOBAL_MEMORY)\n",
        "    accountability = AccountabilityAgent(\"AccountabilityAgent\", GLOBAL_MEMORY)\n",
        "\n",
        "    trend_result = trend_agent.run(user_profile[\"niche\"], user_profile[\"platform\"])\n",
        "    memory_result = memory_agent.run()\n",
        "\n",
        "    handoff = strategist.run(trend_result, memory_result, time_window_hours)\n",
        "    accountability.initialize_state(handoff)\n",
        "\n",
        "    return handoff"
      ],
      "metadata": {
        "id": "CtlTfIi0-T03"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### üñ•Ô∏è Gradio UI and Agent Deployment (Simulation)\n",
        "\n",
        "This cell deploys the Gradio user interface, providing the interactive layer for the agent system. The UI demonstrates:\n",
        "* Clear visualization of the `MemoryBank` data (tasks, history).\n",
        "* The **Loop Agent** process via the \"Check-in\" tab.\n",
        "* **Observability** via the \"Logs\" tab.\n",
        "\n",
        "The launch of this UI via Colab/Kaggle Notebook simulates a basic **Agent Deployment**."
      ],
      "metadata": {
        "id": "e1Zj15MWMUSg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Cell 7: Gradio UI ‚Äì Improved UX with check-in history (Final Fix for Markdown Error)\n",
        "\n",
        "import gradio as gr\n",
        "from datetime import datetime\n",
        "\n",
        "# helper: format tasks for Dataframe (list-of-lists)\n",
        "def tasks_to_table_rows(tasks):\n",
        "    rows = []\n",
        "    for t in tasks:\n",
        "        # Added emoji for visual status\n",
        "        status_emoji = \"‚óªÔ∏è\" if t.get(\"status\") == \"pending\" else \"‚úÖ\"\n",
        "        # FIX: Using single quotes to avoid SyntaxError\n",
        "        description_with_emoji = f\"{status_emoji} {t.get('description')}\"\n",
        "        rows.append([t.get(\"task_id\"), description_with_emoji, t.get(\"status\"), t.get(\"due_time\")])\n",
        "    return rows\n",
        "\n",
        "# helper: compute progress percent\n",
        "def compute_progress(tasks):\n",
        "    if not tasks:\n",
        "        return 0\n",
        "    done = sum(1 for t in tasks if t.get(\"status\") == \"done\")\n",
        "    total = len(tasks)\n",
        "    return int((done / total) * 100)\n",
        "\n",
        "# helper: render a simple ASCII-like progress bar string\n",
        "def render_progress_bar(pct):\n",
        "    filled = int((pct / 100) * 20)\n",
        "    bar = \"[\" + \"#\" * filled + \"-\" * (20 - filled) + f\"] {pct}%\"\n",
        "    return bar\n",
        "\n",
        "# New helper: get ID of the most recently created plan\n",
        "def get_latest_plan_id():\n",
        "    plans = GLOBAL_MEMORY.list_content_plans()\n",
        "    if plans:\n",
        "        return plans[-1][\"id\"]\n",
        "    return None\n",
        "\n",
        "# UI helper functions (these reuse previously defined orchestrator/agents/memory)\n",
        "def ui_generate_plan(name, niche, platform, hours):\n",
        "    if not name or not niche:\n",
        "        # FIX: Return raw string for the Markdown output (first item)\n",
        "        return \"Please enter your name and niche.\", gr.update(value=[], headers=[\"task_id\",\"description\",\"status\",\"due_time\"]), gr.update(choices=[], value=[], interactive=False), gr.update(value=\"\"), gr.update(choices=[], value=None), gr.update(value=\"\")\n",
        "\n",
        "    try:\n",
        "        hours_int = int(hours)\n",
        "    except Exception:\n",
        "        hours_int = 48\n",
        "\n",
        "    handoff = run_full_planning_cycle(\n",
        "        name=name,\n",
        "        niche=niche,\n",
        "        platform=platform,\n",
        "        time_window_hours=hours_int,\n",
        "    )\n",
        "\n",
        "    plan_id = handoff[\"content_plan_id\"]\n",
        "    plan = GLOBAL_MEMORY.get_content_plan(plan_id)\n",
        "\n",
        "    if not plan:\n",
        "        # FIX: Return raw string for the Markdown output (first item)\n",
        "        return \"Plan creation failed. Try again.\", gr.update(value=[], headers=[\"task_id\",\"description\",\"status\",\"due_time\"]), gr.update(choices=[], value=[], interactive=False), gr.update(value=\"\"), gr.update(choices=[], value=None), gr.update(value=\"\")\n",
        "\n",
        "    summary_md = f\"\"\"### ‚úÖ New Content Plan Created\\n\n",
        "**Plan ID:** `{plan_id}`\n",
        "**Topic:** **{plan['topic']}**\n",
        "**Deadline (approx):** {plan['deadline']}\n",
        "\n",
        "> Use the Plan ID above in the *Check-in* tab to report progress or pick from *All Plans*.\n",
        "\"\"\"\n",
        "    task_rows = tasks_to_table_rows(plan[\"tasks\"])\n",
        "    checklist_descs = [t[\"description\"] for t in plan[\"tasks\"]]\n",
        "    plan_summary_label = f\"{plan_id} ‚Äî {plan['topic']} (status: {plan.get('status','unknown')})\"\n",
        "\n",
        "    all_plans_choices, _ = ui_list_plans()\n",
        "\n",
        "    # üåü FIX: Return raw Markdown string (summary_md) for the first output\n",
        "    return (summary_md,\n",
        "            gr.update(value=task_rows),\n",
        "            gr.update(choices=checklist_descs, value=[], interactive=True),\n",
        "            gr.update(value=plan_summary_label),\n",
        "            gr.update(choices=all_plans_choices, value=plan_summary_label),\n",
        "            gr.update(value=plan_id))\n",
        "\n",
        "\n",
        "def ui_list_plans():\n",
        "    plans = GLOBAL_MEMORY.list_content_plans()\n",
        "    if not plans:\n",
        "        return [], \"No plans found yet. Create a plan first.\"\n",
        "\n",
        "    dropdown_items = []\n",
        "    for p in reversed(plans):  # newest first\n",
        "        label = f\"{p['id']} ‚Äî {p['topic']} (status: {p.get('status','unknown')})\"\n",
        "        dropdown_items.append(label)\n",
        "    return dropdown_items, \"Select a plan to view details and check-in.\"\n",
        "\n",
        "def ui_view_plan(plan_label):\n",
        "    if not plan_label:\n",
        "        # FIX: Return raw string for the Markdown output (first item)\n",
        "        return \"Please select a plan.\", [], gr.update(value=\"0%\"), \"\", \"\"\n",
        "\n",
        "    plan_id = plan_label.split(\" ‚Äî \")[0]\n",
        "    plan = GLOBAL_MEMORY.get_content_plan(plan_id)\n",
        "    if not plan:\n",
        "        # FIX: Return raw string for the Markdown output (first item)\n",
        "        return \"Plan not found.\", [], gr.update(value=\"0%\"), \"\", \"\"\n",
        "\n",
        "    progress_pct = compute_progress(plan[\"tasks\"])\n",
        "    progress_bar = render_progress_bar(progress_pct)\n",
        "\n",
        "    md = f\"\"\"### üìã Plan Details\\n**Plan ID:** `{plan['id']}`\\n**Topic:** **{plan['topic']}**\\n**Created:** {plan['created_at']}\\n**Deadline:** {plan['deadline']}\\n**Status:** **{plan['status']}**\\n\\n**Progress:** {progress_bar}\\n\"\"\"\n",
        "\n",
        "    # Build check-in timeline markdown\n",
        "    checkins = plan.get(\"checkins\", [])\n",
        "    if checkins:\n",
        "        timeline_lines = [\"\\n### ‚è±Ô∏è Check-in History\"]\n",
        "        for c in reversed(checkins):  # newest first\n",
        "            ts = c.get(\"timestamp\")\n",
        "            completed = c.get(\"completed_ids\", [])\n",
        "            blockers = c.get(\"blockers\", \"\")\n",
        "            energy = c.get(\"energy\", None)\n",
        "            coach = c.get(\"coaching_excerpt\", \"\")\n",
        "            timeline_lines.append(f\"  - **{ts}** ‚Äî completed: `{completed}` ‚Äî energy: {energy} ‚Äî blockers: {blockers}\")\n",
        "            if coach:\n",
        "                timeline_lines.append(f\"    - coaching: {coach}\")\n",
        "        timeline_md = \"\\n\".join(timeline_lines)\n",
        "    else:\n",
        "        timeline_md = \"\\n\\n_No check-ins recorded yet for this plan._\"\n",
        "\n",
        "    # FIX: Return raw string for the Markdown output (first item)\n",
        "    return md + timeline_md, tasks_to_table_rows(plan[\"tasks\"]), gr.update(value=str(progress_pct) + \"%\"), plan.get('seo_raw','(none)')[:1000], plan.get('outline_raw','(none)')[:1200]\n",
        "\n",
        "def ui_check_in_from_checklist(plan_id, selected_task_descs, blockers, energy_level):\n",
        "    if not plan_id:\n",
        "        # FIX: Return raw string for the Markdown output (first item)\n",
        "        return \"Please select or enter a Plan ID.\", gr.update(value=[], headers=[\"task_id\",\"description\",\"status\",\"due_time\"]), gr.update(value=\"0%\"), gr.update(choices=[], value=[], interactive=True), gr.update(choices=[], value=None), gr.update(value=\"\")\n",
        "\n",
        "    p = GLOBAL_MEMORY.get_content_plan(plan_id)\n",
        "    if not p:\n",
        "        # FIX: Return raw string for the Markdown output (first item)\n",
        "        return f\"Plan ID {plan_id} not found.\", gr.update(value=[], headers=[\"task_id\",\"description\",\"status\",\"due_time\"]), gr.update(value=\"0%\"), gr.update(choices=[], value=[], interactive=True), gr.update(choices=[], value=None), gr.update(value=\"\")\n",
        "\n",
        "    # Convert descriptions back to task_ids\n",
        "    desc_to_id = {t[\"description\"]: t[\"task_id\"] for t in p[\"tasks\"]}\n",
        "    completed_ids = [desc_to_id[d] for d in (selected_task_descs or []) if d in desc_to_id]\n",
        "\n",
        "    try:\n",
        "        energy = int(energy_level) if energy_level is not None else None\n",
        "    except Exception:\n",
        "        energy = None\n",
        "\n",
        "    user_updates = {\n",
        "        \"completed_task_ids\": completed_ids,\n",
        "        \"blockers\": blockers or \"\",\n",
        "        \"energy_level\": energy,\n",
        "    }\n",
        "\n",
        "    acc_agent = AccountabilityAgent(\"AccountabilityAgent\", GLOBAL_MEMORY)\n",
        "    try:\n",
        "        result = acc_agent.run_check_in(plan_id, user_updates)\n",
        "    except ValueError as e:\n",
        "        # FIX: Return raw string for the Markdown output (first item)\n",
        "        return f\"Error: {e}\", gr.update(value=[], headers=[\"task_id\",\"description\",\"status\",\"due_time\"]), gr.update(value=\"0%\"), gr.update(choices=[], value=[], interactive=True), gr.update(choices=[], value=None), gr.update(value=\"\")\n",
        "\n",
        "    plan = GLOBAL_MEMORY.get_content_plan(plan_id)\n",
        "    if not plan:\n",
        "        # FIX: Return raw string for the Markdown output (first item)\n",
        "        return \"Plan missing after check-in.\", gr.update(value=[], headers=[\"task_id\",\"description\",\"status\",\"due_time\"]), gr.update(value=\"0%\"), gr.update(choices=[], value=[], interactive=True), gr.update(choices=[], value=None), gr.update(value=\"\")\n",
        "\n",
        "    status_md = f\"### üìä Plan Status\\n**Status:** {result['plan_status']}  \\n**Next Check-in (suggested):** {result['next_check_in']}\"\n",
        "    coaching_md = f\"### üß† Coaching\\n{result['coaching']}\"\n",
        "    combined_md = status_md + \"\\n\\n\" + coaching_md\n",
        "\n",
        "    task_rows = tasks_to_table_rows(result[\"tasks\"])\n",
        "    progress_pct = compute_progress(result[\"tasks\"])\n",
        "\n",
        "    # Re-populate checklist with current tasks and their completion status\n",
        "    current_checklist_choices = [t[\"description\"] for t in plan[\"tasks\"]]\n",
        "    selected_in_checklist = [t[\"description\"] for t in plan[\"tasks\"] if t[\"status\"] == \"done\"]\n",
        "\n",
        "    updated_dropdown_choices, _ = ui_list_plans()\n",
        "\n",
        "    # üåü FIX: Return raw Markdown string (combined_md) for the first output\n",
        "    return (combined_md,\n",
        "            gr.update(value=task_rows),\n",
        "            gr.update(value=str(progress_pct) + \"%\"),\n",
        "            gr.update(value=selected_in_checklist, choices=current_checklist_choices, interactive=True),\n",
        "            gr.update(choices=updated_dropdown_choices, value=plan_id),\n",
        "            gr.update(value=plan_id))\n",
        "\n",
        "def ui_show_logs():\n",
        "    logs = get_logs()\n",
        "    if not logs:\n",
        "        return \"No logs yet. Run a plan and a check-in first.\"\n",
        "    lines = [\"### üîç Recent agent logs\\n\"]\n",
        "    for log in logs[-25:]:\n",
        "        ts = log.get(\"timestamp\")\n",
        "        agent = log.get(\"agent\")\n",
        "        inp = log.get(\"input\")\n",
        "        lines.append(f\"- `{ts}` **{agent}** ‚Äì *{inp}*\")\n",
        "    return \"\\n\".join(lines)\n",
        "\n",
        "def ui_get_user_profile_data():\n",
        "    profile = GLOBAL_MEMORY.get_user_profile() or {}\n",
        "    return profile.get(\"name\", \"\"), profile.get(\"niche\", \"\"), profile.get(\"platform\", \"youtube\"), profile.get(\"upload_goal_per_week\", 1)\n",
        "\n",
        "def ui_save_profile(name, niche, platform, upload_goal):\n",
        "    try:\n",
        "        upload_goal_int = int(upload_goal)\n",
        "        if upload_goal_int <= 0: raise ValueError(\"Upload goal must be positive.\")\n",
        "    except ValueError:\n",
        "        return \"Upload goal must be a positive integer.\"\n",
        "\n",
        "    ensure_user_profile(name, niche, platform, upload_goal_int)\n",
        "    return \"User profile saved successfully!\"\n",
        "\n",
        "# Build the Gradio Blocks UI\n",
        "with gr.Blocks(title=\"Creator Strategy + Optimizer (Improved UX + History)\") as demo:\n",
        "    gr.Markdown(\n",
        "        \"\"\"\n",
        "# üé¨ Creator Strategy + Optimizer Agent\n",
        "\n",
        "Features:\n",
        "- Create a 48h content plan driven by Trend + Memory + Strategist agents\n",
        "- Browse all plans, view details, and see a timeline of check-ins\n",
        "- Check off tasks via a visual checklist and submit progress\n",
        "- All check-ins are stored in the plan history so you can learn patterns\n",
        "\"\"\"\n",
        "    )\n",
        "\n",
        "    # Plan Content tab\n",
        "    with gr.Tab(\"Plan Content\") as tab_plan_content:\n",
        "        gr.Markdown(\n",
        "            \"\"\"## üöÄ Generate New Content Plan\\n_Enter your details and let the AI agents craft your next content plan._\\n\"\"\"\n",
        "        )\n",
        "        with gr.Row():\n",
        "            with gr.Column(scale=3):\n",
        "                name_in = gr.Textbox(label=\"Your Name\", value=\"Creator\", interactive=True)\n",
        "                niche_in = gr.Textbox(label=\"Your Niche\", value=\"personal finance for students\", interactive=True)\n",
        "                platform_in = gr.Dropdown(label=\"Platform\", choices=[\"youtube\", \"blog\", \"podcast\"], value=\"youtube\", interactive=True)\n",
        "                hours_in = gr.Number(label=\"Time window (hours)\", value=48, precision=0, interactive=True)\n",
        "                btn_plan = gr.Button(\"Generate Content Plan\")\n",
        "                plan_feedback = gr.Markdown()\n",
        "            with gr.Column(scale=2):\n",
        "                gr.Markdown(\"#### Preview: Tasks for the new plan\")\n",
        "                tasks_df = gr.Dataframe(headers=[\"task_id\",\"description\",\"status\",\"due_time\"], interactive=False)\n",
        "                checklist = gr.CheckboxGroup(label=\"Quick checklist (check and go to Check-in tab to submit)\", choices=[], interactive=False)\n",
        "                recent_plan_id_output = gr.Textbox(label=\"Latest Plan ID\", interactive=False, visible=False) # Hidden, used for internal state\n",
        "\n",
        "        def plan_click_handler(name, niche, platform, hours):\n",
        "            summary_md_update, task_rows, checklist_update, _, all_plans_dropdown_update, latest_plan_id_val = ui_generate_plan(name, niche, platform, hours)\n",
        "\n",
        "            return (summary_md_update, task_rows, checklist_update,\n",
        "                    latest_plan_id_val, # for recent_plan_id_output\n",
        "                    all_plans_dropdown_update, # for plan_dropdown\n",
        "                    gr.update(value=latest_plan_id_val) # for plan_id_in_checkin\n",
        "                   )\n",
        "\n",
        "        btn_plan.click(\n",
        "            fn=plan_click_handler,\n",
        "            inputs=[name_in, niche_in, platform_in, hours_in],\n",
        "            outputs=[\n",
        "                plan_feedback, tasks_df, checklist,\n",
        "                recent_plan_id_output,\n",
        "                gr.Dropdown(elem_id=\"plan_dropdown_all_plans\"), # Target in All Plans tab\n",
        "                gr.Textbox(elem_id=\"plan_id_in_checkin\") # Target in Check-in tab\n",
        "            ]\n",
        "        )\n",
        "\n",
        "    # All Plans tab\n",
        "    with gr.Tab(\"All Plans\") as tab_all_plans:\n",
        "        gr.Markdown(\n",
        "            \"\"\"## üóìÔ∏è View All Content Plans\\n_Select a plan from the dropdown to see its details and check-in history._\\n\"\"\"\n",
        "        )\n",
        "        with gr.Row():\n",
        "            plan_dropdown = gr.Dropdown(label=\"All Plans (newest first)\", choices=[], value=None, interactive=True, elem_id=\"plan_dropdown_all_plans\")\n",
        "            btn_refresh = gr.Button(\"Refresh Plans\")\n",
        "        with gr.Row():\n",
        "            plan_detail_md = gr.Markdown()\n",
        "        with gr.Row():\n",
        "            plan_tasks_df = gr.Dataframe(headers=[\"task_id\",\"description\",\"status\",\"due_time\"], interactive=False)\n",
        "            plan_progress = gr.Textbox(label=\"Progress (percent)\", interactive=False)\n",
        "\n",
        "        # Define Markdown components for SEO and Outline within Accordions\n",
        "        with gr.Accordion(\"SEO Details\", open=False):\n",
        "            seo_display = gr.Markdown()\n",
        "        with gr.Accordion(\"Content Outline\", open=False):\n",
        "            outline_display = gr.Markdown()\n",
        "\n",
        "        def refresh_plans_handler():\n",
        "            labels, msg = ui_list_plans()\n",
        "            return gr.update(choices=labels, value=None), gr.update(value=msg)\n",
        "\n",
        "        btn_refresh.click(fn=refresh_plans_handler, inputs=None, outputs=[plan_dropdown, plan_detail_md])\n",
        "\n",
        "        def on_plan_select_handler(selected_label):\n",
        "            if not selected_label:\n",
        "                return gr.update(value=\"Select a plan\"), gr.update(value=[], headers=[\"task_id\",\"description\",\"status\",\"due_time\"]), gr.update(value=\"0%\"), gr.update(value=\"\"), gr.update(value=\"\"), gr.update(value=\"\")\n",
        "\n",
        "            md_output, task_rows, progress_pct, seo_content, outline_content = ui_view_plan(selected_label)\n",
        "            plan_id = selected_label.split(' ‚Äî ')[0]\n",
        "\n",
        "            # FIX: Returns update objects/strings based on component type\n",
        "            return (gr.update(value=md_output),\n",
        "                    gr.update(value=task_rows),\n",
        "                    progress_pct,\n",
        "                    gr.update(value=seo_content),\n",
        "                    gr.update(value=outline_content),\n",
        "                    gr.update(value=plan_id))\n",
        "\n",
        "        plan_dropdown.change(\n",
        "            fn=on_plan_select_handler,\n",
        "            inputs=[plan_dropdown],\n",
        "            outputs=[\n",
        "                plan_detail_md, plan_tasks_df, plan_progress,\n",
        "                seo_display, outline_display, # Directly update accordions' content\n",
        "                gr.Textbox(elem_id=\"plan_id_in_checkin\") # Also update check-in tab\n",
        "            ]\n",
        "        )\n",
        "\n",
        "    # Check-in tab\n",
        "    with gr.Tab(\"Check-in\") as tab_checkin:\n",
        "        gr.Markdown(\n",
        "            \"\"\"## ‚úÖ Check-in Your Progress\\n_Report on completed tasks, blockers, and energy levels for your active plan._\\n\"\"\"\n",
        "        )\n",
        "        with gr.Row():\n",
        "            plan_id_in = gr.Textbox(label=\"Plan ID (from 'Plan Content' or 'All Plans')\", elem_id=\"plan_id_in_checkin\", interactive=True)\n",
        "        with gr.Row():\n",
        "            checklist_in = gr.CheckboxGroup(label=\"Tasks to mark as completed (select & submit)\", choices=[], interactive=True)\n",
        "        with gr.Row():\n",
        "            blockers_in = gr.Textbox(label=\"Blockers (what got in the way?)\", lines=2, interactive=True)\n",
        "            energy_in = gr.Slider(minimum=1, maximum=5, step=1, value=3, label=\"Energy level (1‚Äì5)\", interactive=True)\n",
        "            btn_submit_checkin = gr.Button(\"Submit Check-in\")\n",
        "        with gr.Row():\n",
        "            checkin_md = gr.Markdown()\n",
        "        with gr.Row():\n",
        "            checkin_tasks_df = gr.Dataframe(headers=[\"task_id\",\"description\",\"status\",\"due_time\"], interactive=False)\n",
        "            checkin_progress = gr.Textbox(label=\"Progress (after check-in)\", interactive=False)\n",
        "\n",
        "        # When user types a plan id, populate checklist choices with descriptions\n",
        "        def prepare_checklist_for_plan(plan_id):\n",
        "            if not plan_id:\n",
        "                return gr.update(choices=[], value=[], interactive=True)\n",
        "            p = GLOBAL_MEMORY.get_content_plan(plan_id)\n",
        "            if not p:\n",
        "                return gr.update(choices=[], value=[], interactive=True)\n",
        "\n",
        "            current_choices = [t[\"description\"] for t in p[\"tasks\"]]\n",
        "            currently_completed = [t[\"description\"] for t in p[\"tasks\"] if t[\"status\"] == \"done\"]\n",
        "            return gr.update(choices=current_choices, value=currently_completed, interactive=True)\n",
        "\n",
        "        plan_id_in.change(fn=prepare_checklist_for_plan, inputs=[plan_id_in], outputs=[checklist_in])\n",
        "\n",
        "        def submit_checkin_handler(plan_id, chosen_descriptions, blockers, energy):\n",
        "            if not plan_id:\n",
        "                return gr.update(value=\"Please enter a Plan ID.\"), gr.update(value=[], headers=[\"task_id\",\"description\",\"status\",\"due_time\"]), gr.update(value=\"0%\"), gr.update(choices=[], value=[], interactive=True), gr.update(choices=[], value=None), gr.update(value=\"\")\n",
        "\n",
        "            md_output, task_rows, progress_pct, updated_checklist_selected, all_plans_dropdown_update_value, checklist_choices_update = ui_check_in_from_checklist(plan_id, chosen_descriptions, blockers, energy)\n",
        "\n",
        "            # FIX: Returns update objects/strings based on component type\n",
        "            return (md_output, # Returned as raw string\n",
        "                    gr.update(value=task_rows),\n",
        "                    gr.update(value=progress_pct),\n",
        "                    gr.update(value=updated_checklist_selected, choices=checklist_choices_update, interactive=True),\n",
        "                    gr.Dropdown(elem_id=\"plan_dropdown_all_plans\"), # Target All Plans dropdown\n",
        "                    gr.Textbox(elem_id=\"plan_id_in_checkin\")) # Maintain current plan_id\n",
        "\n",
        "        btn_submit_checkin.click(\n",
        "            fn=submit_checkin_handler,\n",
        "            inputs=[plan_id_in, checklist_in, blockers_in, energy_in],\n",
        "            outputs=[\n",
        "                checkin_md, checkin_tasks_df, checkin_progress, checklist_in, # Current tab outputs\n",
        "                gr.Dropdown(elem_id=\"plan_dropdown_all_plans\"), # Target All Plans dropdown\n",
        "                gr.Textbox(elem_id=\"plan_id_in_checkin\") # Maintain current plan_id\n",
        "            ]\n",
        "        )\n",
        "\n",
        "        # When tab is selected, populate plan_id_in with the latest plan if available\n",
        "        @tab_checkin.select\n",
        "        def load_latest_plan_into_checkin():\n",
        "            latest_id = get_latest_plan_id()\n",
        "            if latest_id:\n",
        "                return gr.update(value=latest_id)\n",
        "            return gr.update(value=\"\")\n",
        "\n",
        "\n",
        "    # User Profile Tab\n",
        "    with gr.Tab(\"User Profile\") as tab_user_profile:\n",
        "        gr.Markdown(\n",
        "            \"\"\"## üë§ Manage Your Profile\\n_Update your personal details to tailor content generation._\\n\"\"\"\n",
        "        )\n",
        "        with gr.Column():\n",
        "            profile_name_in = gr.Textbox(label=\"Name\", interactive=True)\n",
        "            profile_niche_in = gr.Textbox(label=\"Niche\", interactive=True)\n",
        "            profile_platform_in = gr.Dropdown(label=\"Platform\", choices=[\"youtube\", \"blog\", \"podcast\"], interactive=True)\n",
        "            profile_upload_goal_in = gr.Number(label=\"Upload Goal per Week\", precision=0, interactive=True)\n",
        "            btn_save_profile = gr.Button(\"Save Profile\")\n",
        "            profile_save_status = gr.Markdown()\n",
        "\n",
        "        @tab_user_profile.select\n",
        "        def load_user_profile_data():\n",
        "            name, niche, platform, upload_goal = ui_get_user_profile_data()\n",
        "            return gr.update(value=name), gr.update(value=niche), gr.update(value=platform), gr.update(value=upload_goal)\n",
        "\n",
        "        btn_save_profile.click(\n",
        "            fn=ui_save_profile,\n",
        "            inputs=[profile_name_in, profile_niche_in, profile_platform_in, profile_upload_goal_in],\n",
        "            outputs=[profile_save_status]\n",
        "        )\n",
        "\n",
        "    # Logs tab\n",
        "    with gr.Tab(\"Logs\") as tab_logs:\n",
        "        gr.Markdown(\n",
        "            \"\"\"## üìù Agent Activity Log\\n_See a trace of all agent interactions and outputs._\\n\"\"\"\n",
        "        )\n",
        "        logs_btn = gr.Button(\"Refresh Logs\")\n",
        "        logs_md = gr.Markdown()\n",
        "        logs_btn.click(fn=ui_show_logs, inputs=None, outputs=logs_md)\n",
        "\n",
        "        @tab_logs.select\n",
        "        def auto_refresh_logs():\n",
        "            return ui_show_logs()\n",
        "\n",
        "demo.launch(share=True, debug=True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "dWj8N7NJ-WSW",
        "outputId": "4e2f1f0d-e842-40f7-afa1-6f482e6003bc"
      },
      "execution_count": null,
      "outputs": [
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Colab notebook detected. This cell will run indefinitely so that you can see errors and logs. To turn off, set debug=False in launch().\n",
            "* Running on public URL: https://ef761fd25feb605329.gradio.live\n",
            "\n",
            "This share link expires in 1 week. For free permanent hosting and GPU upgrades, run `gradio deploy` from the terminal in the working directory to deploy to Hugging Face Spaces (https://huggingface.co/spaces)\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<div><iframe src=\"https://ef761fd25feb605329.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/gradio/blocks.py:1891: UserWarning: A function (load_user_profile_data) returned too many output values (needed: 0, returned: 4). Ignoring extra values.\n",
            "    Output components:\n",
            "        []\n",
            "    Output values returned:\n",
            "        [{'value': 'TrueCrimeTime', '__type__': 'update'}, {'value': 'True Crime Reports', '__type__': 'update'}, {'value': 'youtube', '__type__': 'update'}, {'value': 1, '__type__': 'update'}]\n",
            "  warnings.warn(\n",
            "/tmp/ipython-input-3971887581.py:53: DeprecationWarning: datetime.datetime.utcnow() is deprecated and scheduled for removal in a future version. Use timezone-aware objects to represent datetimes in UTC: datetime.datetime.now(datetime.UTC).\n",
            "  return datetime.utcnow()\n",
            "/tmp/ipython-input-3971887581.py:53: DeprecationWarning: datetime.datetime.utcnow() is deprecated and scheduled for removal in a future version. Use timezone-aware objects to represent datetimes in UTC: datetime.datetime.now(datetime.UTC).\n",
            "  return datetime.utcnow()\n",
            "/usr/local/lib/python3.12/dist-packages/gradio/blocks.py:1891: UserWarning: A function (auto_refresh_logs) returned too many output values (needed: 0, returned: 1). Ignoring extra values.\n",
            "    Output components:\n",
            "        []\n",
            "    Output values returned:\n",
            "        [\"### üîç Recent agent logs\n",
            "\n",
            "- `2025-12-01T12:54:44` **TrendTool** ‚Äì *niche=True Crime updates, platform=youtube*\n",
            "- `2025-12-01T12:54:44` **TrendAgent** ‚Äì *niche=True Crime updates, platform=youtube*\n",
            "- `2025-12-01T12:54:58` **MemoryAgent** ‚Äì *Analyze memory*\n",
            "- `2025-12-01T12:55:12` **StrategistAgent** ‚Äì *Choose topic*\n",
            "- `2025-12-01T12:55:20` **SEOTool** ‚Äì *topic=Legacy Cases with Lingering Questions and New (Unofficial) Scrutiny - specifically, an in-depth analysis of a recently released documentary or podcast series re-examining a well-known, unsolved historical true crime case.*\n",
            "- `2025-12-01T12:55:36` **StrategistAgent** ‚Äì *Outline + steps*\n",
            "- `2025-12-01T12:59:59` **TrendTool** ‚Äì *niche=personal finance for students, platform=youtube*\n",
            "- `2025-12-01T12:59:59` **TrendAgent** ‚Äì *niche=personal finance for students, platform=youtube*\n",
            "- `2025-12-01T13:00:05` **MemoryAgent** ‚Äì *Analyze memory*\n",
            "- `2025-12-01T13:00:14` **StrategistAgent** ‚Äì *Choose topic*\n",
            "- `2025-12-01T13:00:22` **SEOTool** ‚Äì *topic=Navigating High Inflation with a Student Budget: A \"Budget With Me\" Approach*\n",
            "- `2025-12-01T13:00:37` **StrategistAgent** ‚Äì *Outline + steps*\n",
            "- `2025-12-01T13:03:07` **TrendTool** ‚Äì *niche=personal finance for students, platform=youtube*\n",
            "- `2025-12-01T13:03:07` **TrendAgent** ‚Äì *niche=personal finance for students, platform=youtube*\n",
            "- `2025-12-01T13:03:18` **MemoryAgent** ‚Äì *Analyze memory*\n",
            "- `2025-12-01T13:03:28` **StrategistAgent** ‚Äì *Choose topic*\n",
            "- `2025-12-01T13:03:38` **SEOTool** ‚Äì *topic=My Actual College Budget: How I Stretched $X00 A Month (and you can too!)*\n",
            "- `2025-12-01T13:03:49` **StrategistAgent** ‚Äì *Outline + steps*\n",
            "- `2025-12-01T13:06:29` **AccountabilityAgent** ‚Äì *Check-in + coaching*\n",
            "- `2025-12-01T13:12:23` **TrendTool** ‚Äì *niche=True Crime Reports, platform=youtube*\n",
            "- `2025-12-01T13:12:23` **TrendAgent** ‚Äì *niche=True Crime Reports, platform=youtube*\n",
            "- `2025-12-01T13:12:29` **MemoryAgent** ‚Äì *Analyze memory*\n",
            "- `2025-12-01T13:12:39` **StrategistAgent** ‚Äì *Choose topic*\"]\n",
            "  warnings.warn(\n",
            "/tmp/ipython-input-3971887581.py:53: DeprecationWarning: datetime.datetime.utcnow() is deprecated and scheduled for removal in a future version. Use timezone-aware objects to represent datetimes in UTC: datetime.datetime.now(datetime.UTC).\n",
            "  return datetime.utcnow()\n",
            "/tmp/ipython-input-3971887581.py:53: DeprecationWarning: datetime.datetime.utcnow() is deprecated and scheduled for removal in a future version. Use timezone-aware objects to represent datetimes in UTC: datetime.datetime.now(datetime.UTC).\n",
            "  return datetime.utcnow()\n",
            "/usr/local/lib/python3.12/dist-packages/gradio/blocks.py:1891: UserWarning: A function (load_latest_plan_into_checkin) returned too many output values (needed: 0, returned: 1). Ignoring extra values.\n",
            "    Output components:\n",
            "        []\n",
            "    Output values returned:\n",
            "        [{'value': 'plan_bd382232', '__type__': 'update'}]\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.12/dist-packages/gradio/blocks.py:1891: UserWarning: A function (load_latest_plan_into_checkin) returned too many output values (needed: 0, returned: 1). Ignoring extra values.\n",
            "    Output components:\n",
            "        []\n",
            "    Output values returned:\n",
            "        [{'value': 'plan_bd382232', '__type__': 'update'}]\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.12/dist-packages/gradio/blocks.py:1891: UserWarning: A function (load_latest_plan_into_checkin) returned too many output values (needed: 0, returned: 1). Ignoring extra values.\n",
            "    Output components:\n",
            "        []\n",
            "    Output values returned:\n",
            "        [{'value': 'plan_bd382232', '__type__': 'update'}]\n",
            "  warnings.warn(\n",
            "/tmp/ipython-input-3971887581.py:53: DeprecationWarning: datetime.datetime.utcnow() is deprecated and scheduled for removal in a future version. Use timezone-aware objects to represent datetimes in UTC: datetime.datetime.now(datetime.UTC).\n",
            "  return datetime.utcnow()\n",
            "/usr/local/lib/python3.12/dist-packages/gradio/blocks.py:1891: UserWarning: A function (load_latest_plan_into_checkin) returned too many output values (needed: 0, returned: 1). Ignoring extra values.\n",
            "    Output components:\n",
            "        []\n",
            "    Output values returned:\n",
            "        [{'value': 'plan_bd382232', '__type__': 'update'}]\n",
            "  warnings.warn(\n",
            "/tmp/ipython-input-3971887581.py:53: DeprecationWarning: datetime.datetime.utcnow() is deprecated and scheduled for removal in a future version. Use timezone-aware objects to represent datetimes in UTC: datetime.datetime.now(datetime.UTC).\n",
            "  return datetime.utcnow()\n",
            "/usr/local/lib/python3.12/dist-packages/gradio/blocks.py:1891: UserWarning: A function (load_user_profile_data) returned too many output values (needed: 0, returned: 4). Ignoring extra values.\n",
            "    Output components:\n",
            "        []\n",
            "    Output values returned:\n",
            "        [{'value': 'TrueCrineTime', '__type__': 'update'}, {'value': 'True Crime YT', '__type__': 'update'}, {'value': 'youtube', '__type__': 'update'}, {'value': 1, '__type__': 'update'}]\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.12/dist-packages/gradio/blocks.py:1891: UserWarning: A function (load_latest_plan_into_checkin) returned too many output values (needed: 0, returned: 1). Ignoring extra values.\n",
            "    Output components:\n",
            "        []\n",
            "    Output values returned:\n",
            "        [{'value': 'plan_bd382232', '__type__': 'update'}]\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.12/dist-packages/gradio/blocks.py:1891: UserWarning: A function (load_latest_plan_into_checkin) returned too many output values (needed: 0, returned: 1). Ignoring extra values.\n",
            "    Output components:\n",
            "        []\n",
            "    Output values returned:\n",
            "        [{'value': 'plan_bd382232', '__type__': 'update'}]\n",
            "  warnings.warn(\n",
            "/tmp/ipython-input-3971887581.py:53: DeprecationWarning: datetime.datetime.utcnow() is deprecated and scheduled for removal in a future version. Use timezone-aware objects to represent datetimes in UTC: datetime.datetime.now(datetime.UTC).\n",
            "  return datetime.utcnow()\n",
            "/usr/local/lib/python3.12/dist-packages/gradio/blocks.py:1891: UserWarning: A function (load_latest_plan_into_checkin) returned too many output values (needed: 0, returned: 1). Ignoring extra values.\n",
            "    Output components:\n",
            "        []\n",
            "    Output values returned:\n",
            "        [{'value': 'plan_bd382232', '__type__': 'update'}]\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.12/dist-packages/gradio/blocks.py:1891: UserWarning: A function (load_latest_plan_into_checkin) returned too many output values (needed: 0, returned: 1). Ignoring extra values.\n",
            "    Output components:\n",
            "        []\n",
            "    Output values returned:\n",
            "        [{'value': 'plan_bd382232', '__type__': 'update'}]\n",
            "  warnings.warn(\n",
            "/tmp/ipython-input-3971887581.py:53: DeprecationWarning: datetime.datetime.utcnow() is deprecated and scheduled for removal in a future version. Use timezone-aware objects to represent datetimes in UTC: datetime.datetime.now(datetime.UTC).\n",
            "  return datetime.utcnow()\n",
            "/tmp/ipython-input-3971887581.py:53: DeprecationWarning: datetime.datetime.utcnow() is deprecated and scheduled for removal in a future version. Use timezone-aware objects to represent datetimes in UTC: datetime.datetime.now(datetime.UTC).\n",
            "  return datetime.utcnow()\n",
            "/usr/local/lib/python3.12/dist-packages/gradio/blocks.py:1891: UserWarning: A function (load_latest_plan_into_checkin) returned too many output values (needed: 0, returned: 1). Ignoring extra values.\n",
            "    Output components:\n",
            "        []\n",
            "    Output values returned:\n",
            "        [{'value': 'plan_bd382232', '__type__': 'update'}]\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.12/dist-packages/gradio/blocks.py:1891: UserWarning: A function (load_user_profile_data) returned too many output values (needed: 0, returned: 4). Ignoring extra values.\n",
            "    Output components:\n",
            "        []\n",
            "    Output values returned:\n",
            "        [{'value': 'TrueCrineTime', '__type__': 'update'}, {'value': 'True Crime YT', '__type__': 'update'}, {'value': 'youtube', '__type__': 'update'}, {'value': 1, '__type__': 'update'}]\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.12/dist-packages/gradio/blocks.py:1891: UserWarning: A function (auto_refresh_logs) returned too many output values (needed: 0, returned: 1). Ignoring extra values.\n",
            "    Output components:\n",
            "        []\n",
            "    Output values returned:\n",
            "        [\"### üîç Recent agent logs\n",
            "\n",
            "- `2025-12-01T12:55:20` **SEOTool** ‚Äì *topic=Legacy Cases with Lingering Questions and New (Unofficial) Scrutiny - specifically, an in-depth analysis of a recently released documentary or podcast series re-examining a well-known, unsolved historical true crime case.*\n",
            "- `2025-12-01T12:55:36` **StrategistAgent** ‚Äì *Outline + steps*\n",
            "- `2025-12-01T12:59:59` **TrendTool** ‚Äì *niche=personal finance for students, platform=youtube*\n",
            "- `2025-12-01T12:59:59` **TrendAgent** ‚Äì *niche=personal finance for students, platform=youtube*\n",
            "- `2025-12-01T13:00:05` **MemoryAgent** ‚Äì *Analyze memory*\n",
            "- `2025-12-01T13:00:14` **StrategistAgent** ‚Äì *Choose topic*\n",
            "- `2025-12-01T13:00:22` **SEOTool** ‚Äì *topic=Navigating High Inflation with a Student Budget: A \"Budget With Me\" Approach*\n",
            "- `2025-12-01T13:00:37` **StrategistAgent** ‚Äì *Outline + steps*\n",
            "- `2025-12-01T13:03:07` **TrendTool** ‚Äì *niche=personal finance for students, platform=youtube*\n",
            "- `2025-12-01T13:03:07` **TrendAgent** ‚Äì *niche=personal finance for students, platform=youtube*\n",
            "- `2025-12-01T13:03:18` **MemoryAgent** ‚Äì *Analyze memory*\n",
            "- `2025-12-01T13:03:28` **StrategistAgent** ‚Äì *Choose topic*\n",
            "- `2025-12-01T13:03:38` **SEOTool** ‚Äì *topic=My Actual College Budget: How I Stretched $X00 A Month (and you can too!)*\n",
            "- `2025-12-01T13:03:49` **StrategistAgent** ‚Äì *Outline + steps*\n",
            "- `2025-12-01T13:06:29` **AccountabilityAgent** ‚Äì *Check-in + coaching*\n",
            "- `2025-12-01T13:12:23` **TrendTool** ‚Äì *niche=True Crime Reports, platform=youtube*\n",
            "- `2025-12-01T13:12:23` **TrendAgent** ‚Äì *niche=True Crime Reports, platform=youtube*\n",
            "- `2025-12-01T13:12:29` **MemoryAgent** ‚Äì *Analyze memory*\n",
            "- `2025-12-01T13:12:39` **StrategistAgent** ‚Äì *Choose topic*\n",
            "- `2025-12-01T13:12:45` **SEOTool** ‚Äì *topic=An Unsolved Mystery or Cold Case featuring bizarre, contradictory, or unique details.*\n",
            "- `2025-12-01T13:13:01` **StrategistAgent** ‚Äì *Outline + steps*\n",
            "- `2025-12-01T13:14:43` **AccountabilityAgent** ‚Äì *Check-in + coaching*\n",
            "- `2025-12-01T13:16:34` **AccountabilityAgent** ‚Äì *Check-in + coaching*\n",
            "- `2025-12-01T14:16:36` **AccountabilityAgent** ‚Äì *Check-in + coaching*\n",
            "- `2025-12-01T17:33:41` **AccountabilityAgent** ‚Äì *Check-in + coaching*\"]\n",
            "  warnings.warn(\n",
            "/tmp/ipython-input-3971887581.py:53: DeprecationWarning: datetime.datetime.utcnow() is deprecated and scheduled for removal in a future version. Use timezone-aware objects to represent datetimes in UTC: datetime.datetime.now(datetime.UTC).\n",
            "  return datetime.utcnow()\n",
            "/tmp/ipython-input-3971887581.py:53: DeprecationWarning: datetime.datetime.utcnow() is deprecated and scheduled for removal in a future version. Use timezone-aware objects to represent datetimes in UTC: datetime.datetime.now(datetime.UTC).\n",
            "  return datetime.utcnow()\n",
            "/usr/local/lib/python3.12/dist-packages/gradio/blocks.py:1891: UserWarning: A function (load_latest_plan_into_checkin) returned too many output values (needed: 0, returned: 1). Ignoring extra values.\n",
            "    Output components:\n",
            "        []\n",
            "    Output values returned:\n",
            "        [{'value': 'plan_bd382232', '__type__': 'update'}]\n",
            "  warnings.warn(\n",
            "/tmp/ipython-input-3971887581.py:53: DeprecationWarning: datetime.datetime.utcnow() is deprecated and scheduled for removal in a future version. Use timezone-aware objects to represent datetimes in UTC: datetime.datetime.now(datetime.UTC).\n",
            "  return datetime.utcnow()\n",
            "/tmp/ipython-input-3971887581.py:53: DeprecationWarning: datetime.datetime.utcnow() is deprecated and scheduled for removal in a future version. Use timezone-aware objects to represent datetimes in UTC: datetime.datetime.now(datetime.UTC).\n",
            "  return datetime.utcnow()\n",
            "/usr/local/lib/python3.12/dist-packages/gradio/blocks.py:1891: UserWarning: A function (load_user_profile_data) returned too many output values (needed: 0, returned: 4). Ignoring extra values.\n",
            "    Output components:\n",
            "        []\n",
            "    Output values returned:\n",
            "        [{'value': 'Creator', '__type__': 'update'}, {'value': 'Study tricks', '__type__': 'update'}, {'value': 'youtube', '__type__': 'update'}, {'value': 1, '__type__': 'update'}]\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.12/dist-packages/gradio/blocks.py:1891: UserWarning: A function (auto_refresh_logs) returned too many output values (needed: 0, returned: 1). Ignoring extra values.\n",
            "    Output components:\n",
            "        []\n",
            "    Output values returned:\n",
            "        [\"### üîç Recent agent logs\n",
            "\n",
            "- `2025-12-01T13:00:37` **StrategistAgent** ‚Äì *Outline + steps*\n",
            "- `2025-12-01T13:03:07` **TrendTool** ‚Äì *niche=personal finance for students, platform=youtube*\n",
            "- `2025-12-01T13:03:07` **TrendAgent** ‚Äì *niche=personal finance for students, platform=youtube*\n",
            "- `2025-12-01T13:03:18` **MemoryAgent** ‚Äì *Analyze memory*\n",
            "- `2025-12-01T13:03:28` **StrategistAgent** ‚Äì *Choose topic*\n",
            "- `2025-12-01T13:03:38` **SEOTool** ‚Äì *topic=My Actual College Budget: How I Stretched $X00 A Month (and you can too!)*\n",
            "- `2025-12-01T13:03:49` **StrategistAgent** ‚Äì *Outline + steps*\n",
            "- `2025-12-01T13:06:29` **AccountabilityAgent** ‚Äì *Check-in + coaching*\n",
            "- `2025-12-01T13:12:23` **TrendTool** ‚Äì *niche=True Crime Reports, platform=youtube*\n",
            "- `2025-12-01T13:12:23` **TrendAgent** ‚Äì *niche=True Crime Reports, platform=youtube*\n",
            "- `2025-12-01T13:12:29` **MemoryAgent** ‚Äì *Analyze memory*\n",
            "- `2025-12-01T13:12:39` **StrategistAgent** ‚Äì *Choose topic*\n",
            "- `2025-12-01T13:12:45` **SEOTool** ‚Äì *topic=An Unsolved Mystery or Cold Case featuring bizarre, contradictory, or unique details.*\n",
            "- `2025-12-01T13:13:01` **StrategistAgent** ‚Äì *Outline + steps*\n",
            "- `2025-12-01T13:14:43` **AccountabilityAgent** ‚Äì *Check-in + coaching*\n",
            "- `2025-12-01T13:16:34` **AccountabilityAgent** ‚Äì *Check-in + coaching*\n",
            "- `2025-12-01T14:16:36` **AccountabilityAgent** ‚Äì *Check-in + coaching*\n",
            "- `2025-12-01T17:33:41` **AccountabilityAgent** ‚Äì *Check-in + coaching*\n",
            "- `2025-12-01T17:43:09` **TrendTool** ‚Äì *niche=Study tricks, platform=youtube*\n",
            "- `2025-12-01T17:43:09` **TrendAgent** ‚Äì *niche=Study tricks, platform=youtube*\n",
            "- `2025-12-01T17:43:21` **MemoryAgent** ‚Äì *Analyze memory*\n",
            "- `2025-12-01T17:43:33` **StrategistAgent** ‚Äì *Choose topic*\n",
            "- `2025-12-01T17:43:40` **SEOTool** ‚Äì *topic=The Easiest Way To Beat Procrastination (No Willpower Required)*\n",
            "- `2025-12-01T17:43:51` **StrategistAgent** ‚Äì *Outline + steps*\n",
            "- `2025-12-01T17:44:33` **AccountabilityAgent** ‚Äì *Check-in + coaching*\"]\n",
            "  warnings.warn(\n",
            "/tmp/ipython-input-3971887581.py:53: DeprecationWarning: datetime.datetime.utcnow() is deprecated and scheduled for removal in a future version. Use timezone-aware objects to represent datetimes in UTC: datetime.datetime.now(datetime.UTC).\n",
            "  return datetime.utcnow()\n",
            "/tmp/ipython-input-3971887581.py:53: DeprecationWarning: datetime.datetime.utcnow() is deprecated and scheduled for removal in a future version. Use timezone-aware objects to represent datetimes in UTC: datetime.datetime.now(datetime.UTC).\n",
            "  return datetime.utcnow()\n",
            "/usr/local/lib/python3.12/dist-packages/gradio/blocks.py:1891: UserWarning: A function (load_latest_plan_into_checkin) returned too many output values (needed: 0, returned: 1). Ignoring extra values.\n",
            "    Output components:\n",
            "        []\n",
            "    Output values returned:\n",
            "        [{'value': 'plan_80f8dc40', '__type__': 'update'}]\n",
            "  warnings.warn(\n",
            "/tmp/ipython-input-3971887581.py:53: DeprecationWarning: datetime.datetime.utcnow() is deprecated and scheduled for removal in a future version. Use timezone-aware objects to represent datetimes in UTC: datetime.datetime.now(datetime.UTC).\n",
            "  return datetime.utcnow()\n"
          ]
        }
      ]
    }
  ]
}